{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11bad78e-8cec-4c18-a3bb-fc6861e11cb0",
   "metadata": {},
   "source": [
    "# Detection and Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201759a5-25e3-417b-bacf-31a58978c536",
   "metadata": {},
   "source": [
    "transfer learning with CNN\n",
    "- need earlier layers in network (but not necessarily the later layers)\n",
    "- can learn about a task from a different task (imagenet -> specific classifier)\n",
    "\n",
    "1. train on imagenet (learns low and high level features)\n",
    "2. freze layers until some layer, then use this as a feature extractor to train another classifier (called finetuning)\n",
    "3. train with bigger dataset\n",
    "\n",
    "transfer learning is the norm, not the exception\n",
    "- for example, CNNs are used to extract features, then do something on top of that\n",
    "- another example: finetune CNN and BERT for vision/language, then combine them for captioning task\n",
    "\n",
    "transfer learning isn't always necessary (training from scratch might work just as well)\n",
    "\n",
    "\"model zoos\" contain pretrained networks with weights\n",
    "\n",
    "for our projects\n",
    "1. find big dataset\n",
    "2. transfer to your specific task\n",
    "\n",
    "image classification example\n",
    "- semantic segmentation\n",
    "- object detection\n",
    "- instance segmentation\n",
    "\n",
    "semantic segmentation\n",
    "- problem statement\n",
    "    - for each image, each pixel is labeled with a category\n",
    "    - at test time: classify each pixel of a *new* image\n",
    "- approach 1: extract patches (need surrounding context), then classify center pixel of that patch with a CNN\n",
    "    - this is inefficient (adjacent patches share most pixels, so it's a waste)\n",
    "- approach 2: convolution\n",
    "    - encode image with convnet, then do classification on top of this\n",
    "    - however, CNNs usually reduce the image size (through pooling or conv)\n",
    "        - to solve this, set conv width, stride, padding etc\n",
    "    - 3xHxW -> DxHxW -> CxHxW (each pixel has C classes)\n",
    "        - argmax on the CxHxW layer to find final classification values\n",
    "    - this approach is still inefficient: conv layers retain size of image\n",
    "        - to solve this, downsample (thru pool/conv) then upsample\n",
    "\n",
    "        - upsampling approaches (all differentiable)\n",
    "            - nearest neighbor: copy operation\n",
    "            - bed of nails: copy values into predetermined location, fill rest with zeros\n",
    "            - max unpooling: remember which pixels were max, then unpool to the same locations (other pixels set to zero)\n",
    "\n",
    "            - transposed convolutions: each pixel in input is mapped to multiple pixels in output (TODO: review)\n",
    "\n",
    "- UNet with residual connections\n",
    "    - residual connections across up/down sampling layers\n",
    "\n",
    "object detection\n",
    "- case 1: single object\n",
    "    - go from 4096 dimensional embedding to 4 values (x,y,w,h)\n",
    "    - do regression on correct box: predicted box (x,y,w,h), correct box (x',y',w',h')\n",
    "    - combine with classification loss, then do backprop\n",
    "\n",
    "- case 2 multiple objects:\n",
    "    - what if there are multiple cats, or dogs, etc\n",
    "    - region proposal: **selective search** finds some number of regions relatively quickly based on \"blobiness\"\n",
    "    - slow R-CNN: find regions of interest (~2k), then feed each one thru CNN\n",
    "    - fast R-CNN: get feature map from pretrained CNN, *then* do bounding box regression and classification\n",
    "        - paper is called \"mask R-CNN\"\n",
    "        - regions are selected from feature space: feature space needs to be mapped into pixel space\n",
    "        - RoI pool: snap to grid cells, max pool within each subregion (TODO: review)\n",
    "        - RoI align: TODO: review\n",
    "        - this made the R-CNN more accurate and faster to train\n",
    "    - faster R-CNN:\n",
    "       - region proposal network: train CNN on ground truth bounding box\n",
    "\n",
    "    - YOLO/SSD/RetinaNET\n",
    "        - TODO: review\n",
    "\n",
    "    - things to think about\n",
    "        - backbone net\n",
    "        - meta architecture (single stage, two stage, etc)\n",
    "        - efficiency\n",
    "        \n",
    "        - bigger, deeper backbone nets do better\n",
    "        - faster R-CNN is slower but more accurate than YOLO/SSD\n",
    "\n",
    "- case 3: instance segmentation\n",
    "    - Mask R-CNN (TODO: review)\n",
    "        - does pose estimation as well\n",
    "\n",
    "beyond 2d object detection\n",
    "- dense captioning = object detection + captioning\n",
    "- dense video captioning\n",
    "- scene graphs = objects + relationships\n",
    "    - visual genome\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
